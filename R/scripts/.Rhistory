cordata <- market[c("Sales","Preis","Costs","Arrivals")]
corr <- round(cor(cordata), 1)
library(ggcorrplot)
ggcorrplot(corr, hc.order = TRUE, type = "lower", lab = TRUE, lab_size = 4,
method="circle", colors = c("blue", "white", "red"), outline.color = "gray",
show.legend = TRUE, show.diag = FALSE, title="Correlogram of Sales variables")
#iv
standard_res <- rstandard(model)
summary(standard_res)
plot(market$Sales, standard_res, xlab='Sales', ylab='Standardized Residuals')
#add horizontal line at 0
abline(0, 0)
#koutsoukos
install.packages("dbscan")
y <- c(5,6,8,7,6,5,3,2,8,7,5,3,8,6,4,7,6,5,4,4,3,5,2)
x <- c(1,2,3,3,3,3,3,3,4,4,4,4,5,5,5,6,6,6,6,7,8,9,9)
plot(x,y, main = " X and Y plot")
library("dbscan")
m <- cbind(x,y)
df <- as.data.frame(m)
dbscan_res <- dbscan(df, eps = 1, minPts = 3)
plot(df, col=dbscan_res$cluster+1, main="DBSCAN", pch = 19)
#Elbow Method for finding the optimal number of clusters
set.seed(123)
# Compute and plot wss for k = 2 to k = 15.
k.max <- 15
wss <- sapply(1:k.max,
function(k){kmeans(df, k, nstart=50,iter.max = 15 )$tot.withinss})
wss
plot(1:k.max, wss,
type="b", pch = 19, frame = FALSE,
xlab="Number of clusters K",
ylab="Total within-clusters sum of squares")
kmeans(df,3)
kmeans(df,4)
decathlon <- read.table("C:\\Users\\Kostas\\Dev\\data_analysis_mf\\datasets\\decathlon.csv",
header=TRUE, sep=";",dec=".", row.names=1, check.names=FALSE)
summary(decathlon)
library(FactoMineR)
#res <- PCA(decathlon, quanti.sup=11:12, quali.sup=13, ncp=Inf)
res <- PCA(decathlon, quanti.sup=11:12, quali.sup=13, ncp=8, graph=FALSE)
decathlon.hcpc <- HCPC(decathlon, kk=Inf, min=3, max=10, consol=TRUE)
res.hcpc <- HCPC(res, kk=Inf, min=3, max=10, consol=TRUE)
decathlon.hcpc <- HCPC(decathlon, kk=Inf, min=3, max=10, consol=TRUE)
res.hcpc <- HCPC(res, kk=Inf, min=3, max=10, consol=TRUE)
decathlon.hcpc <- HCPC(decathlon, kk=Inf, min=3, max=10, consol=TRUE)
res.hcpc <- HCPC(res, kk=Inf, min=3, max=10, consol=TRUE)
colnames(decathlon) = c("100m",
+                         "Long.jump",
+                         "Shot.put",
+                         "High.jump",
+                         "400m",
+                         "110m.hurdle",
+                         "Discus",
+                         "Pole.vault",
+                         "Javeline",
+                         "1500m",
+                         "Rank",
+                         "Points",
+                         "Competition")
View(decathlon)
mat = matrix(1:25,ncol = 5)
scal = scale(mat,center = T)
View(mat)
View(scal)
remove = decathlon[-c(1,13)]
View(remove)
View(decathlon)
View(remove)
View(decathlon)
View(remove)
View(decathlon)
View(remove)
kmeans_algo = kmeans(remove,centers = 5)
View(kmeans_algo)
kmeans_algo$cluster
print_clus = function(x)
{
view = print(kmeans_algo)
}
View(print_clus)
print_clus(kmeans_algo$cluster)
View(decathlon)
View(remove)
capital <- read.csv("C:\\Users\\Kostas\\Dev\\data_analysis_mf\\datasets\\capital.csv", sep = ";")
plot(prop.table(table(capital$balance, capital$gender)))
#i
prop.table(table(capital$balance, capital$gender))
#i - barplot
gender <- table(capital$gender)
barplot(gender, ylim=c(0,250), ylab = "Balance", xlab = "Gender",
main = "Balance ~ Gender", col = c('green', '#1F77B4'), legend = TRUE)
#i - pie
pie(gender, main = "Pie balance ~ gender", col = c('green', '#1F77B4'), legend = TRUE)
#ii - boxplots
boxplot(capital, main = 'Boxplot for balance andgender')
boxplot(capital$balance, main="Balance boxplot", ylab="Balance")
boxplot(capital$gender, main="Gender boxplot", ylab="Gender")
boxplot(capital$balance ~ capital$gender, main="Balance ~ Gender boxplot", xlab = "Gender", ylab = "Balance")
#iii
summary(capital)
sd(capital$balance)
sd(capital$gender)
#iv
qqnorm(capital$balance)
qqline(capital$balance)
qqnorm(capital$gender)
qqline(capital$gender)
data <- read.delim("C:\\Users\\Kostas\\Dev\\data_analysis_mf\\datasets\\OctopusF.txt")
View(data)
#Task 1
w <- data$Weight
is.vector(w)
summary(w)
sd(w)
#Task 2
h <- hist(w, xlim=c(40,2400), ylim = c(0, 60), main = "Octopus Histogram", xlab = "Weight")
text(h$mids, h$counts, labels = h$counts, adj = c(0.5, - 0.5))
#Task3
qqnorm(w, main='Normal')
qqline(w)
#confidence interval
mean <- mean(w)
sd <- sd(w)
n <- 240
error <- qnorm(0.975)*sd/sqrt(n)
left <- mean-error
right <- mean+error
left
right
#koutsoukos
library(readxl)
concrete <- read_excel("C:\\Users\\Kostas\\Dev\\data_analysis_mf\\datasets\\Concrete_Data.xls")
#koutsoukos
library(readxl)
concrete <- read_excel("C:\\Users\\Kostas\\Dev\\data_analysis_mf\\datasets\\Concrete_Data.xls")
View(concrete)
#Normalize concrete data
normalize <- function(x) {
return((x - min(x)) / (max(x) - min(x)))
}
concrete_norm <- as.data.frame(lapply(concrete, normalize))
View(concrete_norm)
View(concrete)
# Confirm that the range is now between zero and one:
summary(concrete_norm$Concrete)
# Create training and test data:
concrete_train <- concrete_norm[1:773, ]
concrete_test <- concrete_norm[774:1030, ]
# Train the neuralnet model:
library(neuralnet)
# One hidden neuron:
set.seed(12345) # to guarantee repeatable results
concrete_model <- neuralnet(formula = Concrete ~ Cement + Slag + Ash + Water + Superplasticizer +
CoarseAggregate + FineAggregate + Age, data = concrete_train)
View(concrete_model)
plot(concrete_model) # multi-layer with a single node
model_results <- compute(concrete_model, concrete_test[1:8]) # compute
View(model_results)
model_results
View(concrete)
model_results2 <- predict(concrete_model, concrete_test[1:8]) # predict
model_results2
predicted_strength <- model_results$net.result
cor(predicted_strength, concrete_test$Concrete)
head(predicted_strength)
concrete_train_original_strength <- concrete[1:773,"Concrete"]
strength_min <- min(concrete_train_original_strength)
strength_max <- max(concrete_train_original_strength)
head(concrete_train_original_strength)
unnormalize <- function(x, min, max) {
return( (max - min)*x + min )
}
strength_pred <- unnormalize(predicted_strength, strength_min, strength_max)
strength_pred
#A more complex neural network topology with 5 hidden neurons:
set.seed(12345) # to guarantee repeatable results
concrete_model2 <- neuralnet(Concrete ~ Cement + Slag + Ash + Water + Superplasticizer +
CoarseAggregate + FineAggregate + Age,
data = concrete_train, hidden = 5)
plot(concrete_model2)
#A more complex neural network topology with 5 hidden neurons:
set.seed(12345) # to guarantee repeatable results
concrete_model2 <- neuralnet(Concrete ~ Cement + Slag + Ash + Water + Superplasticizer +
CoarseAggregate + FineAggregate + Age,
data = concrete_train, hidden = 5)
#Evaluate with compute
model_results2 <- compute(concrete_model2, concrete_test[1:8])
predicted_strength2 <- model_results2$net.result
cor(predicted_strength2, concrete_test$Concrete)
head(predicted_strength2)
concrete_train_original_strength <- concrete[1:773,"Concrete"]
strength_min <- min(concrete_train_original_strength)
strength_max <- max(concrete_train_original_strength)
head(concrete_train_original_strength)
unnormalize <- function(x, min, max) {
return( (max - min)*x + min )
}
strength_pred <- unnormalize(predicted_strength, strength_min, strength_max)
strength_pred
#koutsoukos
library(readxl)
market <- read_excel("C:\\Users\\Kostas\\Dev\\data_analysis_mf\\datasets\\market.xlsx")
#i
model <- lm(Sales ~ Preis + Costs + Arrivals , data = market)
summary(model)
summary(model)$coefficient
#ii
modelCosts <- lm(Sales ~ Preis, data = market)
summary(modelCosts)
modelArrivals <- lm(Sales ~ Arrivals, data = market)
summary(modelArrivals)
modelPrice <- lm(Sales ~ Preis, data = market)
summary(modelPrice)
#iii
cordata <- market[c("Sales","Preis","Costs","Arrivals")]
corr <- round(cor(cordata), 1)
library(ggcorrplot)
ggcorrplot(corr, hc.order = TRUE, type = "lower", lab = TRUE, lab_size = 4,
method="circle", colors = c("blue", "white", "red"), outline.color = "gray",
show.legend = TRUE, show.diag = FALSE, title="Correlogram of Sales variables")
#iv
standard_res <- rstandard(model)
summary(standard_res)
plot(market$Sales, standard_res, xlab='Sales', ylab='Standardized Residuals')
#add horizontal line at 0
abline(0, 0)
#koutsoukos
library(readxl)
mf <- read_excel("C:\\Users\\Kostas\\Dev\\data_analysis_mf\\datasets\\mf.xls")
#contingency table
table(mf$`Dollar Claim Amount`, mf$Shift)
#ii
contigency_table <- table(mf$`Complaint Code`, mf$`Manufacturing Plant`)
results <- chisq.test(contigency_table)
round(results$expected)
#iii
boise <- mf[(mf$`Manufacturing Plant` == 1),]$`Dollar Claim Amount`
salt <- mf[(mf$`Manufacturing Plant` == 2),]$`Dollar Claim Amount`
t.test(boise, salt, conf.level = 0.98)
#koutsoukos
install.packages("dbscan")
y <- c(5,6,8,7,6,5,3,2,8,7,5,3,8,6,4,7,6,5,4,4,3,5,2)
x <- c(1,2,3,3,3,3,3,3,4,4,4,4,5,5,5,6,6,6,6,7,8,9,9)
plot(x,y, main = " X and Y plot")
library("dbscan")
m <- cbind(x,y)
df <- as.data.frame(m)
dbscan_res <- dbscan(df, eps = 1, minPts = 3)
plot(df, col=dbscan_res$cluster+1, main="DBSCAN", pch = 19)
set.seed(123)
# Compute and plot wss for k = 2 to k = 15.
k.max <- 15
wss <- sapply(1:k.max,
function(k){kmeans(df, k, nstart=50,iter.max = 15 )$tot.withinss})
wss
plot(1:k.max, wss,
type="b", pch = 19, frame = FALSE,
xlab="Number of clusters K",
ylab="Total within-clusters sum of squares")
kmeans(df,3)
clustersNum <- kmeans(df,3)
plot(df,col=clustersNum$cluster)
plot(df,col=clustersNum$cluster, pch = 19)
clustersNum <- kmeans(df,4)
plot(df,col=clustersNum$cluster, pch = 19)
library(pROC)
library(ROCR)
class <- c('+','+','-','-','+','+','-','-','+','-')
m1 <- c(0.73,0.69,0.44,0.55,0.67,0.47,0.08,0.15,0.45,0.35)
m2 <- c(0.61,0.03,0.68,0.31,0.45,0.09,0.38,0.05,0.01,0.04)
df <- data.frame(class,m1,m2)
View(df)
pred1 <- prediction(df$m1,df$class)
pred2 <- prediction(df$m2,df$class)
View(pred1)
roc1 <- performance(pred1,"tpr","fpr")
roc2 <- performance(pred2,"tpr","fpr")
plot(roc1, col="blue", main='M1 - M2 ROC CURVES')
plot(roc2, col="green", add=TRUE)
## Add Legend
legend("bottomright", c("m1", "m2"), lty=1,
col = c("blue", "green"), bty="n")
library(caret)
confusionMatrix(df$class, df$m1)
confusionMatrix(df$class, df$m1)
df
table(class,m1>0.5) # assuming threshold to be 0.5
#Precision : TP / (TP+FP)
precision <- 3/(3+1) #0.75
#Recall : TP / (TP+FN)
recall <- 3/(3+2) #0.6
#F Score : (2*Precision*Recall) / (Precision+Recall)
f <- 2*precision*recall/(precision+recall) #0.66
#Precision : TP / (TP+FP)
precision <- 3/(3+1) #0.75
precision
#Recall : TP / (TP+FN)
recall <- 3/(3+2) #0.6
recall
#F Score : (2*Precision*Recall) / (Precision+Recall)
f <- 2*precision*recall/(precision+recall) #0.66
f
#---------------------------------------------------------------------------------------------------
#ii
table(class,m2>0.5) # assuming threshold to be 0.5
precision2 <- 1/(1+1) #0.5
precision2
recall2 <- 1/(1+4)  #0.2
recall2
f2 <- 2*precision2*recall2/(precision2+recall2) #0.28
f2
#---------------------------------------------------------------------------------------------------
#iii
table(class,m1>0.1) # assuming threshold to be 0.1
#Precision : TP / (TP+FP)
precision3 <- 5/(5+4) #0.55
precision3
#Recall : TP / (TP+FN)
recall3 <- 5/(5+0) #1
recall3
#F Score : (2*Precision*Recall) / (Precision+Recall)
f3 <- 2*precision*recall/(precision+recall) #0.71
f3
#F Score : (2*Precision*Recall) / (Precision+Recall)
f3 <- 2*precision3*recall3/(precision3+recall3) #0.71
f3
decathlon <- read.table("C:\\Users\\Kostas\\Dev\\data_analysis_mf\\datasets\\decathlon.csv",
header=TRUE, sep=";",dec=".", row.names=1, check.names=FALSE)
decathlon <- read.table("C:\\Users\\Kostas\\Dev\\data_analysis_mf\\datasets\\decathlon.csv",
header=TRUE, sep=";",dec=".", row.names=1, check.names=FALSE)
summary(decathlon)
library(FactoMineR)
#res <- PCA(decathlon, quanti.sup=11:12, quali.sup=13, ncp=Inf)
res <- PCA(decathlon, quanti.sup=11:12, quali.sup=13, ncp=8, graph=FALSE)
View(res)
decathlon.hcpc <- HCPC(decathlon, kk=Inf, min=3, max=10, consol=TRUE)
res.hcpc <- HCPC(res, kk=Inf, min=3, max=10, consol=TRUE)
x1 = matrix(1:25,ncol = 5)
x2 = scale(x1,center = T)
View(x1)
clean = decathlon[-c(1,13)]
kmeans_algo = kmeans(clean,centers = 5)
kmeans_algo$cluster
print_clus = function(x)
{
view = print(kmeans_algo)
}
print_clus(kmeans_algo$cluster)
results.kmeans <- kmeans(scale(decathlon[,1:10], centers = 5))
results.kmeans <- kmeans(scale(decathlon[,1:10], centers = 5))
results.kmeans <- kmeans(scale(decathlon[,1:10]), centers=5)
results.kmeans
decathlon[,1:10]
clean = scale(decathlon[,1:10])
View(clean)
View(decathlon)
results.kmeans <- kmeans(clean, centers=5)
results.kmeans
results.kmeans <- kmeans(clean, centers=4)
results.kmeans
plot(results.kmeans)
plot(results.kmeans, col=results.kmeans$cluster, pch = 19)
is.data.frame(results.kmeans)
dff <- as.data.frame(results.kmeans)
results <- kmeans(clean, centers=4)
results
plot(results, col=results.kmeans$cluster, pch = 19)
dff <- as.data.frame(results)
table(df)
id <- c(1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20)
gender <- c('M','M','M','M','M','M','F','F','F','F','M','M','M','M','F','F','F','F','F','F')
gender <- as.factor(gender)
gender <- unclass(gender)
car <- c('Family','Sports','Sports','Sports','Sports','Sports','Sports','Sports','Sports','Luxury',
'Family','Family','Family','Luxury','Luxury','Luxury','Luxury','Luxury','Luxury','Luxury')
car <- as.factor(car)
car <- unclass(car)
shirt <- c('Small','Medium','Medium','Large','Extra Large','Extra Large','Small','Small','Medium',
'Large','Large','Extra Large','Medium','Extra Large','Small','Small','Medium','Medium','Medium','Large')
shirt <- as.factor(shirt)
shirt <- unclass(shirt)
class <- c('C0','C0','C0','C0','C0','C0','C0','C0','C0','C0','C1','C1','C1','C1','C1','C1','C1','C1','C1','C1')
class <- as.factor(class)
class <- unclass(class)
df <- data.frame(ID=id,Gender=gender,Car=car,Shirt=shirt,Class=class)
id <- c(1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20)
gender <- c('M','M','M','M','M','M','F','F','F','F','M','M','M','M','F','F','F','F','F','F')
gender <- as.factor(gender)
gender <- unclass(gender)
car <- c('Family','Sports','Sports','Sports','Sports','Sports','Sports','Sports','Sports','Luxury',
'Family','Family','Family','Luxury','Luxury','Luxury','Luxury','Luxury','Luxury','Luxury')
car <- as.factor(car)
car <- unclass(car)
shirt <- c('Small','Medium','Medium','Large','Extra Large','Extra Large','Small','Small','Medium',
'Large','Large','Extra Large','Medium','Extra Large','Small','Small','Medium','Medium','Medium','Large')
shirt <- as.factor(shirt)
shirt <- unclass(shirt)
class <- c('C0','C0','C0','C0','C0','C0','C0','C0','C0','C0','C1','C1','C1','C1','C1','C1','C1','C1','C1','C1')
class <- as.factor(class)
class <- unclass(class)
df <- data.frame(ID=id,Gender=gender,Car=car,Shirt=shirt,Class=class)
View(df)
id <- c(1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20)
gender <- c('M','M','M','M','M','M','F','F','F','F','M','M','M','M','F','F','F','F','F','F')
car <- c('Family','Sports','Sports','Sports','Sports','Sports','Sports','Sports','Sports','Luxury',
'Family','Family','Family','Luxury','Luxury','Luxury','Luxury','Luxury','Luxury','Luxury')
shirt <- c('Small','Medium','Medium','Large','Extra Large','Extra Large','Small','Small','Medium',
'Large','Large','Extra Large','Medium','Extra Large','Small','Small','Medium','Medium','Medium','Large')
class <- c('C0','C0','C0','C0','C0','C0','C0','C0','C0','C0','C1','C1','C1','C1','C1','C1','C1','C1','C1','C1')
df <- data.frame(ID=id,Gender=gender,Car=car,Shirt=shirt,Class=class)
View(df)
table(df$Class)
table(df$C1)
#The Gini index is 1 minus the sum of the fraction of records belonging to i at a given node t.
#i
Gini.1 <- 1 - (1/1)^2 - (0/1)^2
Gini.2 <- 1 - (1/1)^2 - (0/1)^2
for (i in 1: 5)
{
# statement
print(i)
}
for (i in 1: 5)
{
Gini.i <- 1 - (1/1)^2 - (0/1)^2
print(Gini.i)
}
#The Gini index is 1 minus the sum of the fraction of records belonging to i at a given node t.
#i
Gini = 0
for (i in 1: 20)
for (i in 1: 20)
{
Gini.i <- 1 - (1/1)^2 - (0/1)^2
Gini = Gini + Gini.i
print(Gini)
}
Gini = 0
for (i in 1: 20)
{
Gini.i <- 1 - (1/1)^2 - (0/1)^2
Gini = Gini + Gini.i
}
Gini
Gini = 0
for (i in 1: 20)
{
Gini.i <- 1 - (1/1)^2 - (0/1)^2
Gini = Gini + Gini.i
}
Gini.ID
Gini.ID = 0
for (i in 1: 20)
{
Gini.i <- 1 - (1/1)^2 - (0/1)^2
Gini.ID = Gini.ID + Gini.i
}
Gini.ID
#iii
table(df$gedner)
#iii
table(df$gender)
View(df)
#iii
table(df$Gender)
c0 <- df[1:10, ]
View(c0)
c1 <- df[11:20,]
View(c1)
#iii
table(c0$gender)
#iii
table(c0$Gender)
#iii
table(c1$Gender)
Gini.Male <- 1 - (6/10)^2 -(4/10)^2
Gini.Female <- 1- (4/10)^2 - (6/10)^2
Gini.Gender <- (10/20)*0.48 + (10/20)*0.48
#iv
table(c0$Car)
table(c1$car)
table(c1$Car)
Gini.Family <- 1- (1/10)^2 - (3/10)^2
#iii
table(c0$gender)
#iii
table(c0$Gender)
#iv
table(c0$Car)
table(c1$Car)
Gini.Sports <- 1- (8/10)^2 - (0/10)^2
Gini.Luxury <- 1- (1/10)^2 - (7/10)^2
Gini.Car <- (4/20)*Gini.Family + (8/20)*Gini.Sports + (8/20)*Gini.Luxury
#iii
table(df$Gender)
table(c0$Gender)
#iv
table(df$Car)
table(c0$Car)
table(c1$Car)
Gini.Family <- 1- (1/4)^2 - (4/4)^2
Gini.Family <- 1- (1/4)^2 - (3/4)^2
Gini.Sports <- 1- (8/8)^2 - (0/8)^2
Gini.Luxury <- 1- (1/8)^2 - (7/8)^2
Gini.Car <- (4/20)*Gini.Family + (8/20)*Gini.Sports + (8/20)*Gini.Luxury
table(df$Gender)
table(c0$Gender)
table(c1$Gender)
Gini.Male <- 1 - (6/10)^2 -(4/10)^2
Gini.Female <- 1- (4/10)^2 - (6/10)^2
Gini.Gender <- (10/20)*0.48 + (10/20)*0.48
